{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Console Collection</H1>\n",
    "<hr>\n",
    "<p>Our original data set consists of a bunch of a values that I copied and pasted about a half a year ago. Using python, hopefully this collection technique will be more efficient.</p>\n",
    "\n",
    "<p>Collection goals:\n",
    "<ul>\n",
    "    <li><strike>Playstation</strike></li>\n",
    "    <li><strike>PS2</strike></li>\n",
    "    <li><strike>Wii</strike></li>\n",
    "    <li><strike>Dreamcast</strike></li>\n",
    "    <li><strike>Genesis</strike></li>\n",
    "    <li><strike>3DS</strike></li>\n",
    "</ul>\n",
    "</p>\n",
    "<br>\n",
    "<p>To scrape games for most consoles, we decided to use a popular game archive site. One issue we encountered is that some cells like Player and Year were the same size, so in consoles that included player counts we had to modify our code.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "import csv\n",
    "\n",
    "def siteScraperNP(website,console):\n",
    "    site = website\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(site,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    links = []\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"/vault/\")}):\n",
    "        links.append(link)\n",
    "\n",
    "    #getting link of first page to index\n",
    "    j = 0\n",
    "    scrapeLinkNum = -1\n",
    "    for link in links:\n",
    "        if re.search(\"#\",str(link)):\n",
    "            #print(\"links\" + \"[%d]\"%(j))\n",
    "            scrapeLinkNum = j\n",
    "        j+=1\n",
    "\n",
    "    #adding the alphabet\n",
    "    scrapeLinks = []\n",
    "    reQuote = re.compile(r'([\\\"\\'])(?:(?=(\\\\?))\\2.)*?\\1')\n",
    "    for i in range(27):\n",
    "        x = str(links[scrapeLinkNum + i])\n",
    "        y = reQuote.search(x)\n",
    "        x = y.group()\n",
    "        x = x.replace(\"\\\"\",\"\")\n",
    "        x = x.replace(\"&amp;\",\"&\")\n",
    "        x = \"website\" + x\n",
    "        scrapeLinks.append(x)\n",
    "    \n",
    "    #getting the titles\n",
    "    titles=[]\n",
    "    for i in scrapeLinks:\n",
    "        site = i\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = Request(site,headers=hdr)\n",
    "        page = urlopen(req)\n",
    "        soup = BeautifulSoup(page)\n",
    "\n",
    "        for t in soup.findAll('tr',{'class':['odd', 'even']}):\n",
    "            titles.append(t)\n",
    "            \n",
    "    consoleName = console\n",
    "    j = 0\n",
    "    games = []\n",
    "    for i in titles:\n",
    "        a = titles[j].findChild(\"a\").contents[0]\n",
    "        try:\n",
    "            b = titles[j].findChild(\"td\",attrs={'style':'width:8%; text-align:center'}).contents[0]\n",
    "        except:\n",
    "            b = 0\n",
    "        try:\n",
    "            c = titles[j].findChild(\"td\",attrs={'style':'width:20%; text-align:center; font-size:10pt'}).contents[0]\n",
    "        except:\n",
    "            c = \"\"\n",
    "\n",
    "        x = [consoleName,a,b,c]\n",
    "        games.append(x)\n",
    "        j+=1\n",
    "    return games\n",
    "\n",
    "def siteScraperP(website,console):\n",
    "    site = website\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(site,headers=hdr)\n",
    "    page = urlopen(req)\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    links = []\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"/vault/\")}):\n",
    "        links.append(link)\n",
    "\n",
    "    #getting link of first page to index\n",
    "    j = 0\n",
    "    scrapeLinkNum = -1\n",
    "    for link in links:\n",
    "        if re.search(\"#\",str(link)):\n",
    "            #print(\"links\" + \"[%d]\"%(j))\n",
    "            scrapeLinkNum = j\n",
    "        j+=1\n",
    "\n",
    "    #adding the alphabet\n",
    "    scrapeLinks = []\n",
    "    reQuote = re.compile(r'([\\\"\\'])(?:(?=(\\\\?))\\2.)*?\\1')\n",
    "    for i in range(27):\n",
    "        x = str(links[scrapeLinkNum + i])\n",
    "        y = reQuote.search(x)\n",
    "        x = y.group()\n",
    "        x = x.replace(\"\\\"\",\"\")\n",
    "        x = x.replace(\"&amp;\",\"&\")\n",
    "        x = \"website\" + x\n",
    "        scrapeLinks.append(x)\n",
    "    \n",
    "    #getting the titles\n",
    "    titles=[]\n",
    "    for i in scrapeLinks:\n",
    "        site = i\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = Request(site,headers=hdr)\n",
    "        page = urlopen(req)\n",
    "        soup = BeautifulSoup(page)\n",
    "\n",
    "        for t in soup.findAll('tr',{'class':['odd', 'even']}):\n",
    "            titles.append(t)\n",
    "            \n",
    "    consoleName = console\n",
    "    j = 0\n",
    "    games = []\n",
    "    for i in titles:\n",
    "        a = titles[j].findChild(\"a\").contents[0]\n",
    "        try:\n",
    "            children = titles[j].findAll(\"td\",attrs={'style':'width:8%; text-align:center'})\n",
    "            b = []\n",
    "            for child in children:\n",
    "                b.append(child.contents[0])\n",
    "            b = b[1]\n",
    "        except:\n",
    "            b = 0\n",
    "        try:\n",
    "            c = titles[j].findChild(\"td\",attrs={'style':'width:20%; text-align:center; font-size:10pt'}).contents[0]\n",
    "        except:\n",
    "            c = \"\"\n",
    "            \n",
    "        x = [consoleName,a,b,c]\n",
    "        games.append(x)\n",
    "        j+=1\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = players , NP = No players\n",
    "\n",
    "ps1games = siteScraperP(\"website\",\"PlayStation\")\n",
    "wiiGames = siteScraperNP(\"website\",\"Wii\")\n",
    "dreamcast = siteScraperP(\"website\",\"Dreamcast\")\n",
    "genesis = siteScraperP(\"website\",\"Genesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outCSV(listname,filename):\n",
    "    with open(filename + \".csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(listname)\n",
    "\n",
    "outCSV(ps1games,\"ps1\")\n",
    "outCSV(wiiGames,\"wii\")\n",
    "outCSV(dreamcast,\"dreamcast\")\n",
    "outCSV(genesis,\"genesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The website doesn't have any entries for 3DS, so we'll need to use wikipedia.<br><br>Thankfully, wikipedia had a large sheet of DS games. Below we scrape the list, drop columns we don't need, and save it as a CSV.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_Nintendo_3DS_games\",header=[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.drop([df.columns[1] , df.columns[3], df.columns[5], df.columns[6], df.columns[7]] ,  axis='columns')\n",
    "a = a.rename(columns={\"North America\": \"release\"})\n",
    "df = a[~a.release.str.contains(\"Unreleased\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-216-aa00a304cbd2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['release2'] = df['release'].astype(str).str[-4:]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Publisher(s)</th>\n",
       "      <th>release</th>\n",
       "      <th>release2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-in-1: Arcade Collection</td>\n",
       "      <td>Gamelion Studios</td>\n",
       "      <td>August 15, 2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001 Spikes</td>\n",
       "      <td>Nicalis</td>\n",
       "      <td>June 3, 2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101 DinoPets 3D</td>\n",
       "      <td>Selectsoft</td>\n",
       "      <td>January 10, 2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101 Penguin Pets 3D</td>\n",
       "      <td>Selectsoft</td>\n",
       "      <td>October 17, 2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101 Pony Pets 3D</td>\n",
       "      <td>Selectsoft</td>\n",
       "      <td>July 24, 2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Zeus Quest Remastered Anagenissis of Gaia</td>\n",
       "      <td>Crazysoft</td>\n",
       "      <td>July 5, 2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>Zig Zag Go</td>\n",
       "      <td>RCMADIAX</td>\n",
       "      <td>January 25, 2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>Zombie Incident</td>\n",
       "      <td>CoderChild</td>\n",
       "      <td>March 5, 2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>Zombie Slayer Diox</td>\n",
       "      <td>JP: CyberfrontWW: UFO Interactive Games</td>\n",
       "      <td>March 22, 2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>Zoo Resort 3D</td>\n",
       "      <td>JP: Marvelous EntertainmentWW: Ubisoft</td>\n",
       "      <td>October 25, 2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1019 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                    10-in-1: Arcade Collection   \n",
       "3                                   1001 Spikes   \n",
       "4                               101 DinoPets 3D   \n",
       "5                           101 Penguin Pets 3D   \n",
       "6                              101 Pony Pets 3D   \n",
       "...                                         ...   \n",
       "1340  Zeus Quest Remastered Anagenissis of Gaia   \n",
       "1341                                 Zig Zag Go   \n",
       "1342                            Zombie Incident   \n",
       "1343                         Zombie Slayer Diox   \n",
       "1344                              Zoo Resort 3D   \n",
       "\n",
       "                                 Publisher(s)           release release2  \n",
       "0                            Gamelion Studios   August 15, 2013     2013  \n",
       "3                                     Nicalis      June 3, 2014     2014  \n",
       "4                                  Selectsoft  January 10, 2013     2013  \n",
       "5                                  Selectsoft  October 17, 2013     2013  \n",
       "6                                  Selectsoft     July 24, 2014     2014  \n",
       "...                                       ...               ...      ...  \n",
       "1340                                Crazysoft      July 5, 2018     2018  \n",
       "1341                                 RCMADIAX  January 25, 2018     2018  \n",
       "1342                               CoderChild     March 5, 2015     2015  \n",
       "1343  JP: CyberfrontWW: UFO Interactive Games    March 22, 2012     2012  \n",
       "1344   JP: Marvelous EntertainmentWW: Ubisoft  October 25, 2011     2011  \n",
       "\n",
       "[1019 rows x 4 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['release2'] = df['release'].astype(str).str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[2], axis='columns')\n",
    "df = df.rename(columns={\"release2\": \"release\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('3DS.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
